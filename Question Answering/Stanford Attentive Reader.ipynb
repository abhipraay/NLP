{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","execution_count":1,"source":["import json\r\n","import pandas as pd\r\n","import numpy as np\r\n","\r\n","def json_to_dataframe(file):\r\n","\r\n","    f = open ( file , \"r\") \r\n","    data = json.loads(f.read())               #loading the json file.\r\n","    iid = []                                  \r\n","    tit = []                                  #Creating empty lists to store values.\r\n","    con = []\r\n","    Que = []\r\n","    Ans_st = []\r\n","    Txt = []\r\n","    \r\n","    for i in range(len(data['data'])):       #Root tag of the json file contains 'title' tag & 'paragraphs' list.\r\n","        \r\n","        title = data['data'][i]['title']\r\n","        for p in range(len(data['data'][i]['paragraphs'])):  # 'paragraphs' list contains 'context' tag & 'qas' list.\r\n","            \r\n","            context = data['data'][i]['paragraphs'][p]['context']\r\n","            for q in range(len(data['data'][i]['paragraphs'][p]['qas'])):  # 'qas' list contains 'question', 'Id' tag & 'answers' list.\r\n","                \r\n","                question = data['data'][i]['paragraphs'][p]['qas'][q]['question']\r\n","                Id = data['data'][i]['paragraphs'][p]['qas'][q]['id']\r\n","                for a in range(len(data['data'][i]['paragraphs'][p]['qas'][q]['answers'])): # 'answers' list contains 'ans_start', 'text' tags. \r\n","                    \r\n","                    ans_start = data['data'][i]['paragraphs'][p]['qas'][q]['answers'][a]['answer_start']\r\n","                    text = data['data'][i]['paragraphs'][p]['qas'][q]['answers'][a]['text']\r\n","                    \r\n","                    tit.append(title)\r\n","                    con.append(context)\r\n","                    Que.append(question)                    # Appending values to lists\r\n","                    iid.append(Id)\r\n","                    Ans_st.append(ans_start)\r\n","                    Txt.append(text)\r\n","\r\n","    print('Done')      # for indication perpose.\r\n","    new_df = pd.DataFrame(columns=['Id','title','context','question','ans_start','text']) # Creating empty DataFrame.\r\n","    new_df.Id = iid\r\n","    new_df.title = tit           #intializing list values to the DataFrame.\r\n","    new_df.context = con\r\n","    new_df.question = Que\r\n","    new_df.ans_start = Ans_st\r\n","    new_df.text = Txt\r\n","    print('Done')      # for indication perpose.\r\n","    final_df = new_df.drop_duplicates(keep='first')  # Dropping duplicate rows from the create Dataframe.\r\n","    return final_df"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-08T09:16:00.443910Z","iopub.execute_input":"2021-09-08T09:16:00.444300Z","iopub.status.idle":"2021-09-08T09:16:00.533086Z","shell.execute_reply.started":"2021-09-08T09:16:00.444201Z","shell.execute_reply":"2021-09-08T09:16:00.531948Z"},"trusted":true}},{"cell_type":"code","execution_count":2,"source":["train_data = json_to_dataframe('/kaggle/input/stanford-question-answering-dataset/train-v1.1.json')\r\n","train_data.head()"],"outputs":[{"output_type":"stream","name":"stdout","text":["Done\n","Done\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>title</th>\n","      <th>context</th>\n","      <th>question</th>\n","      <th>ans_start</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5733be284776f41900661182</td>\n","      <td>University_of_Notre_Dame</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>To whom did the Virgin Mary allegedly appear i...</td>\n","      <td>515</td>\n","      <td>Saint Bernadette Soubirous</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5733be284776f4190066117f</td>\n","      <td>University_of_Notre_Dame</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>What is in front of the Notre Dame Main Building?</td>\n","      <td>188</td>\n","      <td>a copper statue of Christ</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5733be284776f41900661180</td>\n","      <td>University_of_Notre_Dame</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n","      <td>279</td>\n","      <td>the Main Building</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5733be284776f41900661181</td>\n","      <td>University_of_Notre_Dame</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>What is the Grotto at Notre Dame?</td>\n","      <td>381</td>\n","      <td>a Marian place of prayer and reflection</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5733be284776f4190066117e</td>\n","      <td>University_of_Notre_Dame</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>What sits on top of the Main Building at Notre...</td>\n","      <td>92</td>\n","      <td>a golden statue of the Virgin Mary</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                         Id                     title  \\\n","0  5733be284776f41900661182  University_of_Notre_Dame   \n","1  5733be284776f4190066117f  University_of_Notre_Dame   \n","2  5733be284776f41900661180  University_of_Notre_Dame   \n","3  5733be284776f41900661181  University_of_Notre_Dame   \n","4  5733be284776f4190066117e  University_of_Notre_Dame   \n","\n","                                             context  \\\n","0  Architecturally, the school has a Catholic cha...   \n","1  Architecturally, the school has a Catholic cha...   \n","2  Architecturally, the school has a Catholic cha...   \n","3  Architecturally, the school has a Catholic cha...   \n","4  Architecturally, the school has a Catholic cha...   \n","\n","                                            question  ans_start  \\\n","0  To whom did the Virgin Mary allegedly appear i...        515   \n","1  What is in front of the Notre Dame Main Building?        188   \n","2  The Basilica of the Sacred heart at Notre Dame...        279   \n","3                  What is the Grotto at Notre Dame?        381   \n","4  What sits on top of the Main Building at Notre...         92   \n","\n","                                      text  \n","0               Saint Bernadette Soubirous  \n","1                a copper statue of Christ  \n","2                        the Main Building  \n","3  a Marian place of prayer and reflection  \n","4       a golden statue of the Virgin Mary  "]},"metadata":{},"execution_count":2}],"metadata":{"execution":{"iopub.status.busy":"2021-09-08T09:16:11.691139Z","iopub.execute_input":"2021-09-08T09:16:11.691501Z","iopub.status.idle":"2021-09-08T09:16:13.862784Z","shell.execute_reply.started":"2021-09-08T09:16:11.691472Z","shell.execute_reply":"2021-09-08T09:16:13.861822Z"},"trusted":true}},{"cell_type":"code","execution_count":3,"source":["import spacy\r\n","spacy_eng = spacy.load('en_core_web_sm')\r\n","\r\n","class Vocabulary:\r\n","    PAD_token = 0   # Used for padding short sentences\r\n","    SOS_token = 1   # Start-of-sentence token\r\n","    EOS_token = 2   # End-of-sentence token\r\n","\r\n","    def __init__(self, name):\r\n","        self.name = name\r\n","        self.word2index = {'<PAD>': 0, '<SOS>': 1, '<EOS>': 2}\r\n","        self.word2count = {}\r\n","        self.index2word = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\"}\r\n","        self.num_words = 3\r\n","        self.num_sentences = 0 \r\n","        self.longest_sentence = 0\r\n","    \r\n","\r\n","\r\n","    def add_word(self, word):\r\n","        if word not in self.word2index:\r\n","            # First entry of word into vocabulary\r\n","            self.word2index[word] = self.num_words\r\n","            self.word2count[word] = 1\r\n","            self.index2word[self.num_words] = word\r\n","            self.num_words += 1\r\n","        else:\r\n","            # Word exists; increase word count\r\n","            self.word2count[word] += 1\r\n","            \r\n","    def tokenizer(self,text):\r\n","        return [tok.text.lower() for tok in spacy_eng.tokenizer(text)]\r\n","    \r\n","    def add_sentence(self, sentence):\r\n","        sentence_len = 0\r\n","        #for word in sentence.split(' '):\r\n","        for word in self.tokenizer(sentence):\r\n","            sentence_len += 1\r\n","            self.add_word(word)\r\n","        if sentence_len > self.longest_sentence:\r\n","            # This is the longest sentence\r\n","            self.longest_sentence = sentence_len\r\n","        # Count the number of sentences\r\n","        self.num_sentences += 1\r\n","\r\n","    def to_word(self, index):\r\n","        return self.index2word[index]\r\n","\r\n","    def to_index(self, word):\r\n","        return self.word2index[word]"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-08T09:16:13.864361Z","iopub.execute_input":"2021-09-08T09:16:13.864739Z","iopub.status.idle":"2021-09-08T09:16:17.778593Z","shell.execute_reply.started":"2021-09-08T09:16:13.864701Z","shell.execute_reply":"2021-09-08T09:16:17.777737Z"},"trusted":true}},{"cell_type":"code","execution_count":4,"source":["# creating the vocabulary \r\n","vocab = Vocabulary('qa')\r\n","vocab_questions = Vocabulary('q')\r\n","\r\n","# adding words to the vocabulary \r\n","for sentence in train_data['context']:\r\n","    vocab.add_sentence(sentence)\r\n","\r\n","for sentence in train_data['question']:\r\n","    vocab.add_sentence(sentence)\r\n","    vocab_questions.add_sentence(sentence)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-08T09:16:17.780308Z","iopub.execute_input":"2021-09-08T09:16:17.780629Z","iopub.status.idle":"2021-09-08T09:18:58.763657Z","shell.execute_reply.started":"2021-09-08T09:16:17.780594Z","shell.execute_reply":"2021-09-08T09:18:58.762753Z"},"trusted":true}},{"cell_type":"code","execution_count":5,"source":["vocab.num_words"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["91507"]},"metadata":{},"execution_count":5}],"metadata":{"execution":{"iopub.status.busy":"2021-09-08T09:18:58.765185Z","iopub.execute_input":"2021-09-08T09:18:58.765558Z","iopub.status.idle":"2021-09-08T09:18:58.771719Z","shell.execute_reply.started":"2021-09-08T09:18:58.765520Z","shell.execute_reply":"2021-09-08T09:18:58.770836Z"},"trusted":true}},{"cell_type":"code","execution_count":6,"source":["sent_idxs = [1]\r\n","questions = []\r\n","contexts = []\r\n","for idx, sentence in enumerate (train_data['question']):\r\n","    i = 0\r\n","    \r\n","    for word in vocab.tokenizer(sentence):\r\n","        sent_idxs.append(vocab.to_index(word))\r\n","        i+=1\r\n","    while i < ((vocab_questions.longest_sentence) + 2):\r\n","        sent_idxs.append(0)\r\n","        i+=1\r\n","    questions.append(sent_idxs)\r\n","    sent_idxs = [1]\r\n","\r\n","# converting list of word tokens to numpy array\r\n","import numpy as np\r\n","questions = np.array(questions)\r\n","questions.shape"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["(87599, 63)"]},"metadata":{},"execution_count":6}],"metadata":{"execution":{"iopub.status.busy":"2021-09-08T09:18:58.773128Z","iopub.execute_input":"2021-09-08T09:18:58.773485Z","iopub.status.idle":"2021-09-08T09:19:12.617884Z","shell.execute_reply.started":"2021-09-08T09:18:58.773451Z","shell.execute_reply":"2021-09-08T09:19:12.617082Z"},"trusted":true}},{"cell_type":"code","execution_count":7,"source":["contexts = []\r\n","sent_idxs = [1]\r\n","for sentence in train_data['context']:\r\n","    i = 0\r\n","    for word in vocab.tokenizer(sentence):\r\n","        sent_idxs.append(vocab.to_index(word))\r\n","        i+=1\r\n","    while i < ((vocab.longest_sentence) + 1):\r\n","        sent_idxs.append(0)\r\n","        i+=1\r\n","    contexts.append(sent_idxs)\r\n","    sent_idxs = [1]\r\n","\r\n","# converting list of word tokens to numpy array\r\n","import numpy as np\r\n","contexts = np.array(contexts)\r\n","contexts.shape"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["(87599, 811)"]},"metadata":{},"execution_count":7}],"metadata":{"execution":{"iopub.status.busy":"2021-09-08T09:19:12.619196Z","iopub.execute_input":"2021-09-08T09:19:12.619547Z","iopub.status.idle":"2021-09-08T09:21:58.951959Z","shell.execute_reply.started":"2021-09-08T09:19:12.619509Z","shell.execute_reply":"2021-09-08T09:21:58.951162Z"},"trusted":true}},{"cell_type":"code","execution_count":8,"source":["for i in range(len(questions)):\r\n","    for j in range(1,vocab_questions.longest_sentence + 1):\r\n","        if questions[i,j] == 0:\r\n","            questions[i,j] = 2\r\n","            break\r\n","for i in range(len(contexts)):\r\n","    for j in range(1,vocab.longest_sentence + 1):\r\n","        if contexts[i,j] == 0:\r\n","            contexts[i,j] = 2\r\n","            break"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-08T09:21:58.953326Z","iopub.execute_input":"2021-09-08T09:21:58.953695Z","iopub.status.idle":"2021-09-08T09:22:08.479091Z","shell.execute_reply.started":"2021-09-08T09:21:58.953656Z","shell.execute_reply":"2021-09-08T09:22:08.478058Z"},"trusted":true}},{"cell_type":"code","execution_count":9,"source":["vocabs = vocab.word2index.keys()\r\n","\r\n","def load_embeds(root_dir):\r\n","    embeddings_index = dict()\r\n","    f = open(root_dir)\r\n","\r\n","    for line in f:\r\n","        values = line.split()\r\n","        word = values[0]\r\n","        coefs = np.asarray(values[1:], dtype='float32')\r\n","        embeddings_index[word] = coefs\r\n","\r\n","    f.close()\r\n","    return embeddings_index\r\n","embeddings_index = load_embeds('../input/glove6b300dtxt/glove.6B.300d.txt')"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-08T09:22:08.482923Z","iopub.execute_input":"2021-09-08T09:22:08.483303Z","iopub.status.idle":"2021-09-08T09:22:54.395003Z","shell.execute_reply.started":"2021-09-08T09:22:08.483256Z","shell.execute_reply":"2021-09-08T09:22:54.394054Z"},"trusted":true}},{"cell_type":"code","execution_count":10,"source":["embeddings_index['the']"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 4.6560e-02,  2.1318e-01, -7.4364e-03, -4.5854e-01, -3.5639e-02,\n","        2.3643e-01, -2.8836e-01,  2.1521e-01, -1.3486e-01, -1.6413e+00,\n","       -2.6091e-01,  3.2434e-02,  5.6621e-02, -4.3296e-02, -2.1672e-02,\n","        2.2476e-01, -7.5129e-02, -6.7018e-02, -1.4247e-01,  3.8825e-02,\n","       -1.8951e-01,  2.9977e-01,  3.9305e-01,  1.7887e-01, -1.7343e-01,\n","       -2.1178e-01,  2.3617e-01, -6.3681e-02, -4.2318e-01, -1.1661e-01,\n","        9.3754e-02,  1.7296e-01, -3.3073e-01,  4.9112e-01, -6.8995e-01,\n","       -9.2462e-02,  2.4742e-01, -1.7991e-01,  9.7908e-02,  8.3118e-02,\n","        1.5299e-01, -2.7276e-01, -3.8934e-02,  5.4453e-01,  5.3737e-01,\n","        2.9105e-01, -7.3514e-03,  4.7880e-02, -4.0760e-01, -2.6759e-02,\n","        1.7919e-01,  1.0977e-02, -1.0963e-01, -2.6395e-01,  7.3990e-02,\n","        2.6236e-01, -1.5080e-01,  3.4623e-01,  2.5758e-01,  1.1971e-01,\n","       -3.7135e-02, -7.1593e-02,  4.3898e-01, -4.0764e-02,  1.6425e-02,\n","       -4.4640e-01,  1.7197e-01,  4.6246e-02,  5.8639e-02,  4.1499e-02,\n","        5.3948e-01,  5.2495e-01,  1.1361e-01, -4.8315e-02, -3.6385e-01,\n","        1.8704e-01,  9.2761e-02, -1.1129e-01, -4.2085e-01,  1.3992e-01,\n","       -3.9338e-01, -6.7945e-02,  1.2188e-01,  1.6707e-01,  7.5169e-02,\n","       -1.5529e-02, -1.9499e-01,  1.9638e-01,  5.3194e-02,  2.5170e-01,\n","       -3.4845e-01, -1.0638e-01, -3.4692e-01, -1.9024e-01, -2.0040e-01,\n","        1.2154e-01, -2.9208e-01,  2.3353e-02, -1.1618e-01, -3.5768e-01,\n","        6.2304e-02,  3.5884e-01,  2.9060e-02,  7.3005e-03,  4.9482e-03,\n","       -1.5048e-01, -1.2313e-01,  1.9337e-01,  1.2173e-01,  4.4503e-01,\n","        2.5147e-01,  1.0781e-01, -1.7716e-01,  3.8691e-02,  8.1530e-02,\n","        1.4667e-01,  6.3666e-02,  6.1332e-02, -7.5569e-02, -3.7724e-01,\n","        1.5850e-02, -3.0342e-01,  2.8374e-01, -4.2013e-02, -4.0715e-02,\n","       -1.5269e-01,  7.4980e-02,  1.5577e-01,  1.0433e-01,  3.1393e-01,\n","        1.9309e-01,  1.9429e-01,  1.5185e-01, -1.0192e-01, -1.8785e-02,\n","        2.0791e-01,  1.3366e-01,  1.9038e-01, -2.5558e-01,  3.0400e-01,\n","       -1.8960e-02,  2.0147e-01, -4.2110e-01, -7.5156e-03, -2.7977e-01,\n","       -1.9314e-01,  4.6204e-02,  1.9971e-01, -3.0207e-01,  2.5735e-01,\n","        6.8107e-01, -1.9409e-01,  2.3984e-01,  2.2493e-01,  6.5224e-01,\n","       -1.3561e-01, -1.7383e-01, -4.8209e-02, -1.1860e-01,  2.1588e-03,\n","       -1.9525e-02,  1.1948e-01,  1.9346e-01, -4.0820e-01, -8.2966e-02,\n","        1.6626e-01, -1.0601e-01,  3.5861e-01,  1.6922e-01,  7.2590e-02,\n","       -2.4803e-01, -1.0024e-01, -5.2491e-01, -1.7745e-01, -3.6647e-01,\n","        2.6180e-01, -1.2077e-02,  8.3190e-02, -2.1528e-01,  4.1045e-01,\n","        2.9136e-01,  3.0869e-01,  7.8864e-02,  3.2207e-01, -4.1023e-02,\n","       -1.0970e-01, -9.2041e-02, -1.2339e-01, -1.6416e-01,  3.5382e-01,\n","       -8.2774e-02,  3.3171e-01, -2.4738e-01, -4.8928e-02,  1.5746e-01,\n","        1.8988e-01, -2.6642e-02,  6.3315e-02, -1.0673e-02,  3.4089e-01,\n","        1.4106e+00,  1.3417e-01,  2.8191e-01, -2.5940e-01,  5.5267e-02,\n","       -5.2425e-02, -2.5789e-01,  1.9127e-02, -2.2084e-02,  3.2113e-01,\n","        6.8818e-02,  5.1207e-01,  1.6478e-01, -2.0194e-01,  2.9232e-01,\n","        9.8575e-02,  1.3145e-02, -1.0652e-01,  1.3510e-01, -4.5332e-02,\n","        2.0697e-01, -4.8425e-01, -4.4706e-01,  3.3305e-03,  2.9264e-03,\n","       -1.0975e-01, -2.3325e-01,  2.2442e-01, -1.0503e-01,  1.2339e-01,\n","        1.0978e-01,  4.8994e-02, -2.5157e-01,  4.0319e-01,  3.5318e-01,\n","        1.8651e-01, -2.3622e-02, -1.2734e-01,  1.1475e-01,  2.7359e-01,\n","       -2.1866e-01,  1.5794e-02,  8.1754e-01, -2.3792e-02, -8.5469e-01,\n","       -1.6203e-01,  1.8076e-01,  2.8014e-02, -1.4340e-01,  1.3139e-03,\n","       -9.1735e-02, -8.9704e-02,  1.1105e-01, -1.6703e-01,  6.8377e-02,\n","       -8.7388e-02, -3.9789e-02,  1.4184e-02,  2.1187e-01,  2.8579e-01,\n","       -2.8797e-01, -5.8996e-02, -3.2436e-02, -4.7009e-03, -1.7052e-01,\n","       -3.4741e-02, -1.1489e-01,  7.5093e-02,  9.9526e-02,  4.8183e-02,\n","       -7.3775e-02, -4.1817e-01,  4.1268e-03,  4.4414e-01, -1.6062e-01,\n","        1.4294e-01, -2.2628e+00, -2.7347e-02,  8.1311e-01,  7.7417e-01,\n","       -2.5639e-01, -1.1576e-01, -1.1982e-01, -2.1363e-01,  2.8429e-02,\n","        2.7261e-01,  3.1026e-02,  9.6782e-02,  6.7769e-03,  1.4082e-01,\n","       -1.3064e-02, -2.9686e-01, -7.9913e-02,  1.9500e-01,  3.1549e-02,\n","        2.8506e-01, -8.7461e-02,  9.0611e-03, -2.0989e-01,  5.3913e-02],\n","      dtype=float32)"]},"metadata":{},"execution_count":10}],"metadata":{"execution":{"iopub.status.busy":"2021-09-08T09:22:54.396608Z","iopub.execute_input":"2021-09-08T09:22:54.397060Z","iopub.status.idle":"2021-09-08T09:22:54.408545Z","shell.execute_reply.started":"2021-09-08T09:22:54.397030Z","shell.execute_reply":"2021-09-08T09:22:54.407470Z"},"trusted":true}},{"cell_type":"code","execution_count":11,"source":["import torch\r\n","def load_embed_weights(embeddings_index, embed_dim, vocab, vocab_size):\r\n","    matrix_len = vocab_size\r\n","    weights_matrix = np.zeros((matrix_len, embed_dim))\r\n","    words_found = 0\r\n","\r\n","    for i, word in enumerate(vocab):\r\n","        try: \r\n","            weights_matrix[i] = embeddings_index[word]\r\n","            words_found += 1\r\n","        except KeyError:\r\n","            weights_matrix[i] = np.random.normal(scale=0.6, size=(embed_dim, ))\r\n","    weights_matrix = torch.tensor(weights_matrix)\r\n","    return weights_matrix\r\n","weights_matrix = load_embed_weights(embeddings_index, 300, vocabs, vocab.num_words)\r\n","weights_matrix.shape"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([91507, 300])"]},"metadata":{},"execution_count":11}],"metadata":{"execution":{"iopub.status.busy":"2021-09-08T09:22:54.410180Z","iopub.execute_input":"2021-09-08T09:22:54.410542Z","iopub.status.idle":"2021-09-08T09:22:56.456276Z","shell.execute_reply.started":"2021-09-08T09:22:54.410507Z","shell.execute_reply":"2021-09-08T09:22:56.455470Z"},"trusted":true}},{"cell_type":"code","execution_count":12,"source":["train_data.head()"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>title</th>\n","      <th>context</th>\n","      <th>question</th>\n","      <th>ans_start</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5733be284776f41900661182</td>\n","      <td>University_of_Notre_Dame</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>To whom did the Virgin Mary allegedly appear i...</td>\n","      <td>515</td>\n","      <td>Saint Bernadette Soubirous</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5733be284776f4190066117f</td>\n","      <td>University_of_Notre_Dame</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>What is in front of the Notre Dame Main Building?</td>\n","      <td>188</td>\n","      <td>a copper statue of Christ</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5733be284776f41900661180</td>\n","      <td>University_of_Notre_Dame</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n","      <td>279</td>\n","      <td>the Main Building</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5733be284776f41900661181</td>\n","      <td>University_of_Notre_Dame</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>What is the Grotto at Notre Dame?</td>\n","      <td>381</td>\n","      <td>a Marian place of prayer and reflection</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5733be284776f4190066117e</td>\n","      <td>University_of_Notre_Dame</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>What sits on top of the Main Building at Notre...</td>\n","      <td>92</td>\n","      <td>a golden statue of the Virgin Mary</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                         Id                     title  \\\n","0  5733be284776f41900661182  University_of_Notre_Dame   \n","1  5733be284776f4190066117f  University_of_Notre_Dame   \n","2  5733be284776f41900661180  University_of_Notre_Dame   \n","3  5733be284776f41900661181  University_of_Notre_Dame   \n","4  5733be284776f4190066117e  University_of_Notre_Dame   \n","\n","                                             context  \\\n","0  Architecturally, the school has a Catholic cha...   \n","1  Architecturally, the school has a Catholic cha...   \n","2  Architecturally, the school has a Catholic cha...   \n","3  Architecturally, the school has a Catholic cha...   \n","4  Architecturally, the school has a Catholic cha...   \n","\n","                                            question  ans_start  \\\n","0  To whom did the Virgin Mary allegedly appear i...        515   \n","1  What is in front of the Notre Dame Main Building?        188   \n","2  The Basilica of the Sacred heart at Notre Dame...        279   \n","3                  What is the Grotto at Notre Dame?        381   \n","4  What sits on top of the Main Building at Notre...         92   \n","\n","                                      text  \n","0               Saint Bernadette Soubirous  \n","1                a copper statue of Christ  \n","2                        the Main Building  \n","3  a Marian place of prayer and reflection  \n","4       a golden statue of the Virgin Mary  "]},"metadata":{},"execution_count":12}],"metadata":{"execution":{"iopub.status.busy":"2021-09-08T09:22:56.457515Z","iopub.execute_input":"2021-09-08T09:22:56.457847Z","iopub.status.idle":"2021-09-08T09:22:56.472512Z","shell.execute_reply.started":"2021-09-08T09:22:56.457810Z","shell.execute_reply":"2021-09-08T09:22:56.471452Z"},"trusted":true}},{"cell_type":"code","execution_count":13,"source":["start_word_idx = []\r\n","for i in range(len(train_data)):\r\n","    context = train_data['context'].iloc[i]\r\n","    text = train_data['text'].iloc[i]\r\n","    start = train_data['ans_start'].iloc[i]\r\n","    idx = len(vocab.tokenizer(text)[0])\r\n","    context = context[:(start+idx)]\r\n","    context = vocab.tokenizer(context)\r\n","    start_word_idx.append(len(context)-1)\r\n","train_data['start_word'] = start_word_idx"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-08T09:22:56.473878Z","iopub.execute_input":"2021-09-08T09:22:56.474609Z","iopub.status.idle":"2021-09-08T09:24:04.133429Z","shell.execute_reply.started":"2021-09-08T09:22:56.474571Z","shell.execute_reply":"2021-09-08T09:24:04.132561Z"},"trusted":true}},{"cell_type":"code","execution_count":14,"source":["train_data['end_word'] = [(train_data['start_word'].iloc[i]+ len(vocab.tokenizer(train_data['text'].iloc[i])) - 1) for i in range(len(train_data))]"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-08T09:24:04.134696Z","iopub.execute_input":"2021-09-08T09:24:04.135033Z","iopub.status.idle":"2021-09-08T09:24:12.610236Z","shell.execute_reply.started":"2021-09-08T09:24:04.134999Z","shell.execute_reply":"2021-09-08T09:24:12.609422Z"},"trusted":true}},{"cell_type":"code","execution_count":15,"source":["train_data.head()"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>title</th>\n","      <th>context</th>\n","      <th>question</th>\n","      <th>ans_start</th>\n","      <th>text</th>\n","      <th>start_word</th>\n","      <th>end_word</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5733be284776f41900661182</td>\n","      <td>University_of_Notre_Dame</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>To whom did the Virgin Mary allegedly appear i...</td>\n","      <td>515</td>\n","      <td>Saint Bernadette Soubirous</td>\n","      <td>102</td>\n","      <td>104</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5733be284776f4190066117f</td>\n","      <td>University_of_Notre_Dame</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>What is in front of the Notre Dame Main Building?</td>\n","      <td>188</td>\n","      <td>a copper statue of Christ</td>\n","      <td>37</td>\n","      <td>41</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5733be284776f41900661180</td>\n","      <td>University_of_Notre_Dame</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n","      <td>279</td>\n","      <td>the Main Building</td>\n","      <td>57</td>\n","      <td>59</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5733be284776f41900661181</td>\n","      <td>University_of_Notre_Dame</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>What is the Grotto at Notre Dame?</td>\n","      <td>381</td>\n","      <td>a Marian place of prayer and reflection</td>\n","      <td>76</td>\n","      <td>82</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5733be284776f4190066117e</td>\n","      <td>University_of_Notre_Dame</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>What sits on top of the Main Building at Notre...</td>\n","      <td>92</td>\n","      <td>a golden statue of the Virgin Mary</td>\n","      <td>17</td>\n","      <td>23</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                         Id                     title  \\\n","0  5733be284776f41900661182  University_of_Notre_Dame   \n","1  5733be284776f4190066117f  University_of_Notre_Dame   \n","2  5733be284776f41900661180  University_of_Notre_Dame   \n","3  5733be284776f41900661181  University_of_Notre_Dame   \n","4  5733be284776f4190066117e  University_of_Notre_Dame   \n","\n","                                             context  \\\n","0  Architecturally, the school has a Catholic cha...   \n","1  Architecturally, the school has a Catholic cha...   \n","2  Architecturally, the school has a Catholic cha...   \n","3  Architecturally, the school has a Catholic cha...   \n","4  Architecturally, the school has a Catholic cha...   \n","\n","                                            question  ans_start  \\\n","0  To whom did the Virgin Mary allegedly appear i...        515   \n","1  What is in front of the Notre Dame Main Building?        188   \n","2  The Basilica of the Sacred heart at Notre Dame...        279   \n","3                  What is the Grotto at Notre Dame?        381   \n","4  What sits on top of the Main Building at Notre...         92   \n","\n","                                      text  start_word  end_word  \n","0               Saint Bernadette Soubirous         102       104  \n","1                a copper statue of Christ          37        41  \n","2                        the Main Building          57        59  \n","3  a Marian place of prayer and reflection          76        82  \n","4       a golden statue of the Virgin Mary          17        23  "]},"metadata":{},"execution_count":15}],"metadata":{"execution":{"iopub.status.busy":"2021-09-08T09:24:12.611532Z","iopub.execute_input":"2021-09-08T09:24:12.611885Z","iopub.status.idle":"2021-09-08T09:24:12.627490Z","shell.execute_reply.started":"2021-09-08T09:24:12.611849Z","shell.execute_reply":"2021-09-08T09:24:12.626591Z"},"trusted":true}},{"cell_type":"code","execution_count":16,"source":["from torch.utils.data import Dataset, DataLoader, random_split\r\n","from torchvision import transforms\r\n","from glob import glob\r\n","from PIL import Image\r\n","import torch\r\n","import torch.nn as nn\r\n","import torch.nn.functional as F\r\n","import numpy as np\r\n","import pandas as pd\r\n","import matplotlib.pyplot as plt\r\n","\r\n","class SquadDataset(Dataset):\r\n","    \r\n","    def __init__(self, train_data,contexts, questions):\r\n","        self.contexts = contexts\r\n","        self.questions = questions \r\n","        self.train_data = train_data\r\n","    \r\n","    def __getitem__(self, index):\r\n","        return self.contexts[index], self.questions[index], self.train_data['start_word'].iloc[index]+1, self.train_data['end_word'].iloc[index]+1\r\n","    def __len__(self):\r\n","        return len(self.questions)\r\n","\r\n","\r\n","data = SquadDataset(train_data, contexts, questions)\r\n"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-08T09:24:12.629029Z","iopub.execute_input":"2021-09-08T09:24:12.629408Z","iopub.status.idle":"2021-09-08T09:24:12.758079Z","shell.execute_reply.started":"2021-09-08T09:24:12.629373Z","shell.execute_reply":"2021-09-08T09:24:12.757300Z"},"trusted":true}},{"cell_type":"code","execution_count":17,"source":["batch_size = 32\r\n","data_len = len(data)\r\n","trainset, valset = random_split(data, [int(0.8*data_len), (data_len - int(0.8*data_len))])\r\n","trainloader = DataLoader(dataset=trainset, batch_size=batch_size, shuffle = True)\r\n","valloader = DataLoader(dataset=valset, batch_size=batch_size, shuffle = True)\r\n"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-08T09:24:12.760001Z","iopub.execute_input":"2021-09-08T09:24:12.760262Z","iopub.status.idle":"2021-09-08T09:24:12.780019Z","shell.execute_reply.started":"2021-09-08T09:24:12.760232Z","shell.execute_reply":"2021-09-08T09:24:12.779257Z"},"trusted":true}},{"cell_type":"code","execution_count":18,"source":["for c,q,s,e in trainloader:\r\n","    for i in q[0]:\r\n","        print(vocab.to_word(int(i)), end = ' ')\r\n","    print()\r\n","    print()\r\n","    for i in c[0]:\r\n","        print(vocab.to_word(int(i)), end = ' ')\r\n","    break"],"outputs":[{"output_type":"stream","name":"stdout","text":["<SOS> who was the commissioner of the arena football league for the first half of 2008 ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n","\n","<SOS> after 12 years as commissioner of the afl , david baker retired unexpectedly on july 25 , 2008 , just two days before arenabowl xxii ; deputy commissioner ed policy was named interim commissioner until baker 's replacement was found . baker explained , \" when i took over as commissioner , i thought it would be for one year . it turned into 12 . but now it 's time . \" <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> "]}],"metadata":{"execution":{"iopub.status.busy":"2021-09-08T09:24:12.781303Z","iopub.execute_input":"2021-09-08T09:24:12.781933Z","iopub.status.idle":"2021-09-08T09:24:12.956732Z","shell.execute_reply.started":"2021-09-08T09:24:12.781890Z","shell.execute_reply":"2021-09-08T09:24:12.955789Z"},"trusted":true}},{"cell_type":"code","execution_count":19,"source":["class Model_1(nn.Module):\r\n","    \r\n","    def __init__(self, embed_size, hidden_size, context_size, vocab_size ):\r\n","        super().__init__()\r\n","        \r\n","        self.embed_size = embed_size\r\n","        self.vocab_size = vocab_size\r\n","        self.hidden_size = hidden_size\r\n","        self.context_size = context_size\r\n","        \r\n","        self.embed = nn.Embedding(num_embeddings = self.vocab_size, embedding_dim = self.embed_size)\r\n","        self.embed.weight.requires_grad = False\r\n","        self.embed.load_state_dict({'weight': weights_matrix})\r\n","\r\n","        \r\n","      \r\n","        self.question_lstm = nn.LSTM(input_size = self.embed_size, hidden_size = self.hidden_size, bidirectional = True, batch_first = True)\r\n","        self.context_lstm = nn.LSTM(input_size = self.embed_size, hidden_size = self.hidden_size, bidirectional = True, batch_first = True)\r\n","        \r\n","        self.attention = nn.Linear(2*self.hidden_size, 2*self.hidden_size, bias = False)\r\n","\r\n","        self.start_fc = nn.Linear(self.context_size, self.context_size)\r\n","        self.end_fc = nn.Linear(self.context_size, self.context_size)\r\n","        \r\n","        \r\n","\r\n","        \r\n","\r\n","    def forward(self, contexts, questions):\r\n","        \r\n","        contexts_embed = self.embed(contexts)\r\n","        questions_embed = self.embed(questions)\r\n","       \r\n","        questions_rep, _ = self.question_lstm(questions_embed)\r\n","        contexts_rep, _ = self.context_lstm(contexts_embed)                     #[64,811, 400]\r\n","        \r\n","        questions_rep = questions_rep[:,-1,:].unsqueeze(1)                      #[64,1, 400]\r\n","        a = []\r\n","        for i in range(contexts_rep.shape[1]):\r\n","            c = self.attention(contexts_rep[:,i,:]).unsqueeze(2)                # [64, 400, 1]\r\n","        \r\n","            c2 = []\r\n","            for batch in range(contexts_rep.shape[0]):\r\n","                c1 = questions_rep[batch,:,:] @ c[batch,:,:]  # [1,1]\r\n","                c2.append(c1)\r\n","            c2 = torch.stack(c2)\r\n","            a.append(c2)                              #[64,1,1]\r\n","        \r\n","        a = torch.stack(a)\r\n","        a = a.permute(1,0,2,3).squeeze(-1).squeeze(-1)\r\n","\r\n","        a = F.softmax(a, dim = 1)    # [64,811]\r\n","        start_probs = self.start_fc(a)    #[64,811]\r\n","        end_probs = self.end_fc(a)        #[64,811]\r\n","        \r\n","        \r\n","        \r\n","        return start_probs, end_probs\r\n","        "],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-08T09:24:12.958017Z","iopub.execute_input":"2021-09-08T09:24:12.958377Z","iopub.status.idle":"2021-09-08T09:24:12.973827Z","shell.execute_reply.started":"2021-09-08T09:24:12.958340Z","shell.execute_reply":"2021-09-08T09:24:12.972919Z"},"trusted":true}},{"cell_type":"code","execution_count":20,"source":["class Model_2(nn.Module):\r\n","    \r\n","    def __init__(self, embed_size, hidden_size, context_size, vocab_size ):\r\n","        super().__init__()\r\n","        \r\n","        self.embed_size = embed_size\r\n","        self.vocab_size = vocab_size\r\n","        self.hidden_size = hidden_size\r\n","        self.context_size = context_size\r\n","        \r\n","        self.embed = nn.Embedding(num_embeddings = self.vocab_size, embedding_dim = self.embed_size)\r\n","        self.embed.weight.requires_grad = False\r\n","        self.embed.load_state_dict({'weight': weights_matrix})\r\n","\r\n","        self.lstm = nn.LSTM(input_size = self.embed_size, hidden_size = self.hidden_size, bidirectional = True, batch_first = True)\r\n","        \r\n","        self.q_fc = nn.Linear(2*self.hidden_size, 2*self.hidden_size)\r\n","        self.c_fc = nn.Linear(4*self.hidden_size, 2*self.hidden_size)\r\n","        \r\n","        self.start_fc = nn.Linear(2*self.hidden_size, 1) \r\n","        \r\n","        self.end_lstm = nn.LSTM(input_size = 2*self.hidden_size, hidden_size = self.hidden_size, bidirectional = True, batch_first = True)\r\n","        self.end_fc = nn.Linear(2*self.hidden_size, 1)\r\n","        \r\n","        self.tanh = nn.Tanh()\r\n","\r\n","    def forward(self, contexts, questions):\r\n","        \r\n","        contexts_embed = self.embed(contexts)\r\n","        questions_embed = self.embed(questions)\r\n","\r\n","        questions_rep, _ = self.lstm(questions_embed)                   # [64,63,400]\r\n","        contexts_rep, _ = self.lstm(contexts_embed)                     #[64,811, 400]\r\n","        \r\n","        questions_rep = self.tanh(self.q_fc(questions_rep))\r\n","        \r\n","        A = []\r\n","        for i in range(questions_rep.shape[0]):\r\n","            A.append(questions_rep[i,:,:] @ contexts_rep[i,:,:].T)\r\n","        A = torch.stack(A)                                           # [64,63,811]  \r\n","        A = F.softmax(A, dim = 2)\r\n","        \r\n","        Q = []\r\n","        for i in range(questions_rep.shape[0]):\r\n","            Q.append(A[i,:,:].T @ questions_rep[i,:,:])  \r\n","        Q = torch.stack(Q)                                          # [64,811,400]\r\n","        \r\n","        M = torch.cat((Q, contexts_rep), dim = -1)\r\n","                   \r\n","        M = self.tanh(self.c_fc(M))   # [64,811,400] \r\n","        \r\n","        start_probs = self.start_fc(M).squeeze(-1)\r\n","        \r\n","        Hf, _ = self.end_lstm(M)                                  # [64,811,400]\r\n","\r\n","        end_probs = self.end_fc(Hf).squeeze(-1)\r\n","        \r\n","        \r\n","        return start_probs, end_probs"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-08T09:24:12.976149Z","iopub.execute_input":"2021-09-08T09:24:12.976478Z","iopub.status.idle":"2021-09-08T09:24:12.993612Z","shell.execute_reply.started":"2021-09-08T09:24:12.976447Z","shell.execute_reply":"2021-09-08T09:24:12.992865Z"},"trusted":true}},{"cell_type":"code","execution_count":21,"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","embed_size = 300\r\n","hidden_size = 200\r\n","context_size = contexts.shape[1]\r\n","vocab_size = vocab.num_words\r\n","\r\n","model1 = Model_1(embed_size, hidden_size, context_size, vocab_size )\r\n","model1 = model1.to(device)\r\n","\r\n","model2 = Model_2(embed_size, hidden_size, context_size, vocab_size )\r\n","model2 = model2.to(device)\r\n","\r\n","criterion = nn.CrossEntropyLoss()\r\n","criterion = criterion.to(device)\r\n","optimizer1 = torch.optim.Adam(model1.parameters(), lr = 1e-2)\r\n","optimizer2 = torch.optim.Adam(model2.parameters(), lr = 1e-2)\r\n"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-08T09:24:12.996431Z","iopub.execute_input":"2021-09-08T09:24:12.996742Z","iopub.status.idle":"2021-09-08T09:24:18.951942Z","shell.execute_reply.started":"2021-09-08T09:24:12.996717Z","shell.execute_reply":"2021-09-08T09:24:18.951100Z"},"trusted":true}},{"cell_type":"code","execution_count":22,"source":["device"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":22}],"metadata":{"execution":{"iopub.status.busy":"2021-09-08T09:24:18.953150Z","iopub.execute_input":"2021-09-08T09:24:18.953557Z","iopub.status.idle":"2021-09-08T09:24:18.959152Z","shell.execute_reply.started":"2021-09-08T09:24:18.953512Z","shell.execute_reply":"2021-09-08T09:24:18.958282Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["import pyprind\r\n","best_loss = 100\r\n","def train(trainloader, model1, model2, criterion, optimizer1, optimizer2):\r\n","    train_loss = []\r\n","    bar = pyprind.ProgBar(len(trainloader), bar_char='█')\r\n","    for batch_idx, (c,q,s,e) in enumerate(trainloader):\r\n","        c = c.to(device)\r\n","        q = q.to(device)\r\n","        s = s.to(device)\r\n","        e = e.to(device)\r\n","        start_probs1, end_probs1 = model1(c,q)\r\n","        start_probs2, end_probs2 = model2(c,q)\r\n","        start_probs = start_probs1 + start_probs2\r\n","        end_probs = start_probs1 + end_probs2\r\n","        optimizer1.zero_grad()\r\n","        optimizer2.zero_grad()\r\n","        loss1 = criterion(start_probs, s)\r\n","        loss2 = criterion(end_probs, e)\r\n","        loss = loss1 + loss2\r\n","        train_loss.append(loss.item())\r\n","        loss.backward()\r\n","        optimizer1.step()\r\n","        optimizer2.step()\r\n","        \r\n","        bar.update()\r\n","        \r\n","        if (batch_idx%5 == 0): \r\n","            print('batch({}/{})  train loss : {}\\n'.format(batch_idx, len(trainloader),np.mean(train_loss)))\r\n","    \r\n","    \r\n","    \r\n","    torch.save(model1.state_dict(), 'weights_model_1.pth')\r\n","    torch.save(model2.state_dict(), 'weights_model_2.pth')\r\n","    best_loss = np.mean(train_loss)\r\n","    "],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-06T02:43:57.722838Z","iopub.status.idle":"2021-09-06T02:43:57.72344Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["epochs = 1\r\n","#model1.load_state_dict(torch.load('../input/qna-weights/weights_model_1.pth'))\r\n","#model2.load_state_dict(torch.load('../input/qna-weights/weights_model_2.pth'))\r\n","for epoch in range(epochs):\r\n","    train(trainloader, model1, model2, criterion, optimizer1, optimizer2)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-06T02:43:57.730696Z","iopub.status.idle":"2021-09-06T02:43:57.731425Z"},"trusted":true}},{"cell_type":"code","execution_count":23,"source":["model1.load_state_dict(torch.load('../input/qna-weights1/weights_model_1.pth'))\r\n","model2.load_state_dict(torch.load('../input/qna-weights1/weights_model_2.pth'))\r\n","for batch_idx, (c,q,s,e) in enumerate(trainloader):\r\n","    c = c.to(device)\r\n","    q = q.to(device)\r\n","    s = s.to(device)\r\n","    e = e.to(device)\r\n","    print(s[1])\r\n","    start_probs1, end_probs1 = model1(c,q)\r\n","    start_probs2, end_probs2 = model2(c,q)\r\n","    start_probs = start_probs1 + start_probs2\r\n","    end_probs = start_probs1 + end_probs2\r\n","    break"],"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(85, device='cuda:0')\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-09-08T09:24:52.868244Z","iopub.execute_input":"2021-09-08T09:24:52.868577Z","iopub.status.idle":"2021-09-08T09:24:58.605292Z","shell.execute_reply.started":"2021-09-08T09:24:52.868547Z","shell.execute_reply":"2021-09-08T09:24:58.604398Z"},"trusted":true}},{"cell_type":"markdown","source":["# Checking for a random question"],"metadata":{}},{"cell_type":"markdown","source":["## question and  predicted answer"],"metadata":{}},{"cell_type":"code","execution_count":77,"source":["t = 3\r\n","print('question: ', end = ' ')\r\n","for i in q[t]:\r\n","    if int(i) == 0:\r\n","        break\r\n","    if i!= 1 and i!=2:\r\n","        print(vocab.to_word(int(i)), end = ' ')\r\n","print()\r\n","print()\r\n","print('actual answer: ', end = ' ')\r\n","for i in range(int(s[t]),(int(e[t])+1)):\r\n","    print(vocab.to_word(int(c[t][i])), end = ' ')\r\n","s1 = torch.argmax(start_probs, dim = 1)\r\n","e1 = torch.argmax(end_probs, dim = 1)\r\n","print()\r\n","print()\r\n","print('predicted answer: ', end = ' ')\r\n","for i in range(int(s1[t]),(int(e1[t])+1)):\r\n","    print(vocab.to_word(int(c[t][i])), end = ' ')\r\n","\r\n"],"outputs":[{"output_type":"stream","name":"stdout","text":["question:  who is he current minority leader ? \n","\n","actual answer:  nancy pelosi \n","\n","predicted answer:  nancy pelosi "]}],"metadata":{"execution":{"iopub.status.busy":"2021-09-08T09:38:35.728926Z","iopub.execute_input":"2021-09-08T09:38:35.729267Z","iopub.status.idle":"2021-09-08T09:38:35.745852Z","shell.execute_reply.started":"2021-09-08T09:38:35.729233Z","shell.execute_reply":"2021-09-08T09:38:35.744720Z"},"trusted":true}}]}